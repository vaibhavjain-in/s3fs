<?php

/**
 * @file
 * Sets up the S3StreamWrapper class to be used as a Drupal file system.
 */

/**
 * The version number of the current release.
 */
define('S3FS_VERSION', '7.x-0.1-dev');

/**
 * Implements hook_stream_wrappers().
 *
 * Create a stream wrapper for S3.
 */
function s3fs_stream_wrappers() {
  return array(
    's3' => array(
      'name' => 'S3 File System',
      'class' => 'S3StreamWrapper',
      'description' => t('Amazon Simple Storage Service'),
    ),
  );
}

/**
 * Implements hook_menu().
 */
function s3fs_menu() {
  $items = array();
  
  $items['admin/config/media/s3fs'] = array(
    'title' => 'S3 File System',
    'description' => 'Configure S3 File System settings.',
    'page callback' => 'drupal_get_form',
    'page arguments' => array('s3fs_admin'),
    'access arguments' => array('administer s3fs'),
  );
  // A special version of system/files/styles/%image_style, based on how
  // the core Image module does it with image_style_deliver().
  $items['s3/files/styles/%image_style'] = array(
    'title' => 'Generate image style in S3',
    'page callback' => 's3fs_image_style_deliver',
    'page arguments' => array(3),
    'access callback' => TRUE,
    'type' => MENU_CALLBACK,
  );
  
  return $items;
}

/**
 * Implements hook_permission().
 */
function s3fs_permission() {
  return array(
    'administer s3fs' => array(
      'title' => t('Administer S3 File System'),
    ),
  );
}

/**
 * Implements hook_help().
 */
function s3fs_help($path, $arg) {
  if ($path == 'admin/config/media/s3fs') {
    if (module_exists('awssdk_ui')) {
      return '<p>' . t('Amazon Web Services authentication can be configured on the <a href="@awssdk_config">AWS SDK configuration page</a>.',
        array('@awssdk_config' => url('admin/config/media/awssdk'))) . '</p>';
    }
    else {
      return '<p>' . t("To configure your Amazon Web Services credentials, enable the 'AWS SDK for PHP UI' module,
        or define those settings in the \$conf array in your site's settings.php file.") . '</p>';
    }
  }
}

/**
 * Implements hook_admin().
 */
function s3fs_admin() {
  $form = array();
  
  $form['s3fs_bucket'] = array(
    '#type'           => 'textfield',
    '#title'          => t('S3 Bucket Name'),
    '#default_value'  => variable_get('s3fs_bucket', ''),
    '#required'       => TRUE,
  );
  $form['s3fs_cname'] = array(
    '#type'           => 'checkbox',
    '#title'          => t('Enable CNAME'),
    '#description'    => t('Serve files from a custom domain by using an appropriately named bucket, e.g. "mybucket.mydomain.com".'),
    '#default_value'  => variable_get('s3fs_cname', 0),
  );
  $form['s3fs_domain'] = array(
    '#type'           => 'textfield',
    '#title'          => t('CDN Domain Name'),
    '#description'    => t('If serving files from CloudFront, the bucket name can differ from the domain name.'),
    '#default_value'  => variable_get('s3fs_domain', ''),
    '#states'         => array(
      'visible' => array(
        ':input[id=edit-s3fs-cname]' => array('checked' => TRUE),
      ),
    ),
  );
  $form['s3fs_customhost'] = array(
    '#type'           => 'checkbox',
    '#title'          => t('Use a Custom Hostname'),
    '#description'    => t('Connect to an S3-compatible storage service other than Amazon.'),
    '#default_value'  => variable_get('s3fs_customhost', FALSE),
  );
  $form['s3fs_hostname'] = array(
    '#type'           => 'textfield',
    '#title'          => t('Hostname'),
    '#description'    => t('Custom service hostname (e.g. objects.dreamhost.com)'),
    '#default_value'  => variable_get('s3fs_hostname', ''),
    '#states'         => array(
      'visible' => array(
        ':input[id=edit-s3fs-customhost]' => array('checked' => TRUE),
      ),
    ),
  );
  $form['s3fs_torrents'] = array(
    '#type' => 'textarea',
    '#title' => t('Torrents'),
    '#description' => t('A list of paths that should be delivered through a torrent url. Enter one value per line e.g. "mydir/*". Paths are relative to the Drupal file directory and use patterns as per <a href="@preg_match">preg_match</a>.', array('@preg_match' => 'http://php.net/preg_match')),
    '#default_value' => variable_get('s3fs_torrents', ''),
    '#rows' => 10,
  );
  $form['s3fs_presigned_urls'] = array(
    '#type' => 'textarea',
    '#title' => t('Presigned URLs'),
    '#description' => t('A list of timeouts and paths that should be delivered through a presigned url. Enter one value per line, in the format timeout|path. e.g. "60|mydir/*". Paths are relative to the Drupal file directory and use patterns as per <a href="@preg_match">preg_match</a>. If no timeout is provided, it defaults to 60 seconds.', array('@preg_match' => 'http://php.net/preg_match')),
    '#default_value' => variable_get('s3fs_presigned_urls', ''),
    '#rows' => 10,
  );
  $form['s3fs_saveas'] = array(
    '#type' => 'textarea',
    '#title' => t('Force Save As'),
    '#description' => t('A list of paths that force the user to save the file, by using the Content-Disposition header. Prevents autoplay of media. Enter one value per line. e.g. "mydir/*". Paths are relative to the Drupal file directory and use patterns as per <a href="@preg_match">preg_match</a>. <b>Files must use a presigned url to use this feature.</b>', array('@preg_match' => 'http://php.net/preg_match')),
    '#default_value' => variable_get('s3fs_saveas', ''),
    '#rows' => 10,
  );
  
  $form['s3fs_refresh_cache'] = array(
    '#type' => 'fieldset',
    '#description' => t("The file metadata cache keeps track of every file that S3 File System writes to (and deletes from) the S3 bucket, so that queries for data about those files (checks for existence, filetype, etc.) don't have to hit S3. This speeds up many operations, most noticeably anything related to images and their derivatives."),
    '#title' => t('File Metadata Cache'),
  );
  $form['s3fs_refresh_cache']['refresh'] = array(
    '#type' => 'submit',
    '#suffix' => '<div class="refresh">' . t("This button queries S3 for the metadata of <i><b>all</b></i> the files in your site's bucket, and saves it to the database. This may take a while for buckets with many thousands of files. <br>It should only be necessary to use this button if you've just installed S3 File System and you need to cache all the pre-existing files in your bucket, or if you need to restore your metadata cache from scratch for some other reason.") . '</div>',
    '#value' => t('Refresh file metadata cache'),
    '#submit' => array('s3fs_refresh_cache_submit'),
  );
  // Push the button closer to its own description, rather than the fieldset's
  // description, and push the disable checkbox away from the description.
  $form['s3fs_refresh_cache']['refresh']['#attached']['css'] = array('#edit-refresh {margin-bottom: 0; margin-top: 1em;} div.refresh {margin-bottom: 1em;}' => array('type' => 'inline'));
  
  $form['s3fs_refresh_cache']['s3fs_ignore_cache'] = array(
    '#type'          => 'checkbox',
    '#title'         => t('Ignore the file metadata cache'),
    '#description'   => t("If you need to debug a problem with S3, you may want to temporarily ignore the file metadata cache. This will make all filesystem reads hit S3 instead of the cache. Please be aware that this will cause an enormous performance loss, and should never be enabled on a production site."),
    '#default_value' => variable_get('s3fs_ignore_cache', 0),
  );
  
  return system_settings_form($form);
}

/**
 * Validates the values on the admin form.
 */
function s3fs_admin_validate($form, &$form_state) {
  $form_state['values']['s3fs_bucket'] = filter_xss($form_state['values']['s3fs_bucket']);
  
  $orig_customhost = variable_get('s3fs_customhost', NULL);
  $orig_hostname = variable_get('s3fs_hostname', NULL);
  $use_temp = variable_get('s3fs_customhost') !== $form_state['values']['s3fs_customhost'] || variable_get('s3fs_hostname') !== $form_state['values']['s3fs_hostname'];
  if ($use_temp) {
    // IF the user changed then, temporarily set the s3fs_customhost and
    // s3fs_hostname variables to their values in the form, so that
    // _s3fs_get_amazons3_client() can get their new values during validation.
    variable_set('s3fs_customhost', $form_state['values']['s3fs_customhost']);
    variable_set('s3fs_hostname', filter_xss($form_state['values']['s3fs_hostname']));
  }
  _s3fs_validate_config($form_state['values']['s3fs_bucket']);
  if ($use_temp) {
    variable_set('s3fs_customhost', $orig_customhost);
    variable_set('s3fs_hostname', $orig_hostname);
  }
}

/**
 * Submit callback for the refresh file metadata cache button.
 */
function s3fs_refresh_cache_submit($form, &$form_state) {
  $form_state['values']['s3fs_domain']         = filter_xss($form_state['values']['s3fs_domain']);
  $form_state['values']['s3fs_torrents']       = filter_xss($form_state['values']['s3fs_torrents']);
  $form_state['values']['s3fs_saveas']         = filter_xss($form_state['values']['s3fs_saveas']);
  $form_state['values']['s3fs_presigned_urls'] = filter_xss($form_state['values']['s3fs_presigned_urls']);
  $form_state['values']['s3fs_bucket']         = filter_xss($form_state['values']['s3fs_bucket']);
  _s3fs_refresh_cache($form_state['values']['s3fs_bucket']);
}

/**
 * Page callback: Generates a derivative in S3, given a style and image path,
 * and then redirects to the generated file.
 *
 * This is a re-write of the core Image module's image_style_deliver() function.
 * It exists to improve the performance of serving newly-created image
 * derivatives from S3.
 *
 * Note to future maintainers: this function is variatic. It accepts two fixed
 * arguments: $style and $scheme, and any number of further arguments, which
 * represent the path to the file in S3 (split on the slahses).
 */
function s3fs_image_style_deliver() {
  // Drupal's black magic calls this function with the image style as arg0,
  // the scheme as arg1, and the full path to the filename split across arg2+.
  // So we need to use PHP's version of variatic functions to get the complete
  // filename.
  $args = func_get_args();
  $style = array_shift($args);
  // The second parameter ($scheme) is unused, since we know we're using s3://.
  array_shift($args);
  $filename = implode('/', $args);
  
  $valid = !empty($style);
  if (!variable_get('image_allow_insecure_derivatives', FALSE) || strpos(ltrim($filename, '\/'), 'styles/') === 0) {
    $valid = $valid && isset($_GET[IMAGE_DERIVATIVE_TOKEN]) && $_GET[IMAGE_DERIVATIVE_TOKEN] === image_style_path_token($style['name'], "s3://$filename");
  }
  if (!$valid) {
    return MENU_ACCESS_DENIED;
  }
  
  $image_uri = "s3://$filename";
  $derivative_uri = image_style_path($style['name'], $image_uri);
  
  // Don't start generating the image if the derivative already exists or if
  // generation is in progress in another thread.
  $lock_name = 's3fs_image_style_deliver:' . $style['name'] . ':' . drupal_hash_base64($image_uri);
  if (!file_exists($derivative_uri)) {
    $lock_acquired = lock_acquire($lock_name);
    if (!$lock_acquired) {
      // Tell client to retry again in 3 seconds. No browsers are currently
      // known to support Retry-After, though.
      drupal_add_http_header('Status', '503 Service Unavailable');
      drupal_add_http_header('Retry-After', 3);
      print t('Image generation in progress. Try again shortly.');
      drupal_exit();
    }
  }
  
  // Try to generate the image, unless another thread just did it while we were
  // acquiring the lock.
  $success = file_exists($derivative_uri) || image_style_create_derivative($style, $image_uri, $derivative_uri);
  
  if (!empty($lock_acquired)) {
    lock_release($lock_name);
  }
  
  if ($success) {
    // Perform a 302 Redirect to the newly-created iamge derivative.
    drupal_goto(file_create_url($derivative_uri));
  }
  else {
    watchdog('image', 'Unable to generate the derived image located at %path.', array('%path' => $derivative_uri));
    drupal_add_http_header('Status', '500 Internal Server Error');
    print t('Error generating image.');
    drupal_exit();
  }
}

/**
 * Checks all the configuration options to ensure that they're valid.
 *
 * @return bool
 *   TRUE if config is good to go, otherwise FALSE.
 */
function _s3fs_validate_config($bucket) {
  try {
    $s3 = _s3fs_get_amazons3_client($bucket);
  }
  catch (AWSException $e) {
    form_set_error('s3fs_bucket', $e->getMessage());
    return FALSE;
  }
  
  try {
    // Test the connection to S3.
    $user_id = $s3->get_canonical_user_id();
    if (empty($user_id['id'])) {
      form_set_error('s3fs_bucket', t('The specified S3 access credentials are invalid.'));
      return FALSE;
    }
    elseif (!$s3->if_bucket_exists($bucket)) {
      form_set_error('s3fs_bucket', t('The bucket "@bucket" does not exist.', array('@bucket' => $bucket)));
      return FALSE;
    }
  }
  catch (RequestCore_Exception $e){
    if (strstr($e->getMessage(), 'SSL certificate problem')) {
      form_set_error('s3fs_bucket', t('There was a problem with the SSL certificate. Try setting AWS_CERTIFICATE_AUTHORITY to true in "libraries/awssdk/config.inc.php". You may also have a curl library (e.g. the default shipped with MAMP) that does not contain trust certificates for the major authorities.'));
      return FALSE;
    }
    else {
      form_set_error('s3fs_bucket', t('There was a problem connecting to S3: @error', array('@error' => $e->getMessage())));
      return FALSE;
    }
  }
  catch (Exception $e) {
    form_set_error('s3fs_bucket', t('There was an unexpected problem using S3: @error', array('@error' => $e->getMessage())));
    return FALSE;
  }

  return TRUE;
}

/**
 * Calls AmazonS3::list_objects() enough times to get all the files in the
 * specified bucket (the API returns at most 1000 per call), and stores their
 * metadata in the cache table. Then it builds the list of folders by analyzing
 * the full pathnames of all the files.
 */
function _s3fs_refresh_cache($bucket) {
  // Bomb out with an error if our configuration settings are invalid.
  if (!_s3fs_validate_config($bucket)) {
    form_set_error('s3fs_refresh_cache][refresh', t('Unable to validate S3 configuration settings.'));
    return;
  }
  $s3 = _s3fs_get_amazons3_client($bucket);
  $metadata_fields = array('uri', 'filesize', 'timestamp', 'dir', 'mode', 'uid');
  
  // Clear the files out of the metadata table, so we can recreate them from
  // scratch. Directories are not erased because empty directories could not
  // be regenerated.
  db_delete('s3fs_file')
    ->condition('dir', 0, '=')
    ->execute();
  
  $marker = NULL;
  do {
    $args = array();
    if (!empty($marker)) {
      $args['marker'] = $marker;
    }
    
    $response = $s3->list_objects($bucket, $args);
    if (!$response->isOK()) {
      drupal_set_message(t('Metadata cache refresh aborted. A @code error occurred: @error.', array('@code' => $response->status, '@error' => $response->body->Message)), 'error');
      return;
    }
    $file_metadata_list = array();
    $folder_metadata_list = array();
    foreach ($response->body->Contents as $object) {
      $s3_metadata = _s3fs_s3_object_to_s3_metadata($object);
      $uri = "s3://{$s3_metadata['Key']}";
      $is_dir = $uri[strlen($uri) - 1] == '/';
      
      if ($is_dir) {
        // There may be files in the S3 bucket pretending to be folders, by
        // having a trailing '/'. Add those to the cache as directories.
        $folder_metadata_list[] = _s3fs_format_metadata(rtrim($uri, '/'), array());
      }
      else {
        $file_metadata_list[] = _s3fs_format_metadata($uri, $s3_metadata);
      }
      
      // If we need to get another page of responces, the final key in the
      // previous page acts as the marker.
      $marker = $s3_metadata['Key'];
    }
    
    // Re-populate the file metadata table with the current page's files.
    $insert_query = db_insert('s3fs_file')
      ->fields($metadata_fields);
    foreach ($file_metadata_list as $metadata) {
      $insert_query->values($metadata);
    }
    
    try {
      $insert_query->execute();
    }
    catch (PDOException $e) {
      if ($e->getCode() == 23000) {
        // This shouldn't ever happen!!!
        // I originally coded this error correction for the case when there are
        // two files in S3 with the same name, but different capitalization. By
        // default, MySQL doesn't allow string keys which are case-insensitive
        // identical, but I found out how to get around that by using utf8_bin
        // collation.
        // Just in case this does ever happen, though, the best we can do is
        // redo each insert one at a time, catching and logging the individual
        // failures.
        foreach ($file_metadata_list as $metadata) {
          try {
            db_insert('s3fs_file')
              ->fields($metadata_fields)
              ->values($metadata)
              ->execute();
          }
          catch (PDOException $e) {
            drupal_set_message(t("The file @uri has the same name as another file in S3, but with different capitalization.
              If you haven't done so already, be sure to run the database update script (drush updb).
              If you've already done that, something is very wrong, and you should post a ticket to the S3 File System issue queue.", array('@uri' => $metadata['uri'])), 'warning');
          }
        }
      }
      else {
        // Other exceptions are unexpected, and should be percolated as normal.
        throw $e;
      }
    }
    
    // Now add the "folders" from S3. We need to use db_merge instead of insert
    // because folders don't get deleted in the first step.
    foreach ($folder_metadata_list as $metadata) {
      db_merge('s3fs_file')
        ->key(array('uri' => $metadata['uri']))
        ->fields($metadata)
        ->execute();
    }
  } while ($response->body->IsTruncated->to_string() == 'true');
  
  // Rebuild the list of directories by looping through all the file URIs to
  // to figure out what their parent directories are.
  $uris = db_query('SELECT uri FROM {s3fs_file} WHERE dir = 0')->fetchAll(PDO::FETCH_COLUMN, 0);
  $folders = array();
  foreach ($uris as $uri) {
    // Record each file's parent directory name, unless it's the root directory.
    $dirname = drupal_dirname($uri);
    if ($dirname && $dirname != 's3://') {
      $folders[$dirname] = $dirname;
    }
  }
  $stream = new S3StreamWrapper();
  foreach ($folders as $folder) {
    $stream->mkdir($folder, NULL, STREAM_MKDIR_RECURSIVE);
  }
  drupal_set_message(t('S3 File System cache refreshed.'));
}

/**
 * Convert file metadata returned from S3 into an array appropriate
 * for insertion into our file metadata cache.
 *
 * @param string $uri
 *   A string containing the uri of the resource to check.
 * @param array $s3_metadata
 *   An array containing the collective metadata for the Amazon S3 object.
 *   The caller may send an empty array here to indicate that the returned
 *   metadata should represent a folder.
 *
 * @return array
 *   An array containing metadata formatted for the file metadata cache.
 */
function _s3fs_format_metadata($uri, $s3_metadata) {
  $metadata = array('uri' => $uri);
  
  if (empty($s3_metadata)) {
    // The caller wants directory metadata, so invent some.
    $metadata['dir'] = 1;
    $metadata['filesize'] = 0;
    $metadata['timestamp'] = time();
    $metadata['uid'] = 'S3 File System';
    // The posix S_IFDIR flag.
    $metadata['mode'] = 0040000;
  }
  else {
    // The caller sent us some actual metadata, so this must be a file.
    if (isset($s3_metadata['Size'])) {
      $metadata['filesize'] = $s3_metadata['Size'];
    }
    if (isset($s3_metadata['LastModified'])) {
      $metadata['timestamp'] = date('U', strtotime((string) $s3_metadata['LastModified']));
    }
    if (isset($s3_metadata['Owner']['ID'])) {
      $metadata['uid'] = (string) $s3_metadata['Owner']['ID'];
    }
    $metadata['dir'] = 0;
    // The S_IFREG posix flag.
    $metadata['mode'] = 0100000;
  }
  // Everything is writeable.
  $metadata['mode'] |= 0777;
  return $metadata;
}

/**
 * Converts objects returned by AmazonS3::get_objects() into s3 metadata arrays
 * compatible with those returned by AmazonS3::get_object_metadata().
 */
function _s3fs_s3_object_to_s3_metadata($object) {
  // This is an "icky" but effective way to do a deep conversion of
  // an object into a multi-dimentional array, found here:
  // http://stackoverflow.com/a/2476954/464318
  return json_decode(json_encode($object), TRUE);
}

class AWSException extends Exception {}

/**
 * Performs all the necessary steps to create and configure an AmazonS3 client
 * object, and returns it to the caller.
 *
 * For performance reasons, only one AmazonS3 client object will ever be created
 * within a single request.
 */
function _s3fs_get_amazons3_client($bucket = NULL) {
  static $s3;
  
  if (!isset($s3)) {
    if (!libraries_load('awssdk')) {
      throw new AWSException(t('Unable to load the AWS SDK. Please check you have installed the library correctly and configured your S3 credentials.'));
    }
    elseif (!class_exists('AmazonS3')) {
      throw new AWSException(t('Cannot load AmazonS3 class. Please ensure that the awssdk library is installed correctly.'));
    }
    $s3 = new AmazonS3();
    
    // When the bucket has a . in its name, we are forced to use "path style"
    // URLs (http://s3.amazonaws.com/bucket-name) instead of the default
    // "DNS style" URLs (http://bucket-name.s3.amazonaws.com) because of the
    // way that newer versions of OpenSSL verify certificate hosts.
    // See: https://forums.aws.amazon.com/thread.jspa?threadID=69108
    if (strpos($bucket, '.') !== FALSE) {
      // TODO: This *might* be incompatible with set_hostname() below.
      // I don't know and can't currently test it.
      $s3->enable_path_style();
    }
    
    // Using SSL makes uploads significantly slower, but is unsafe to disable.
    // I'm still looking for a better solution. -- coredumperror 2013/07/12
    // Using AWS SDK for PHP 2.0 may work. -- coredumperror 2013/10/08
    /*
    $s3->disable_ssl();
    */
    
    if (variable_get('s3fs_customhost', FALSE)) {
      $hostname = variable_get('s3fs_hostname', '');
      if (empty($hostname)) {
        $msg = t('The Custom Hostname option is enabled, but no custom host domain has been set.');
        drupal_set_message($msg, 'error');
        watchdog('S3 File System', $msg, array(), WATCHDOG_ERROR);
      }
      else {
        $s3->set_hostname($hostname);
      }
    }
  }
  
  return $s3;
}
